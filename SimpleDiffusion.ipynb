{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleDiffusion",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Diffusion\n",
        "\n",
        "This Colab notebook provides a simple way for users to generate images using the [Stable Diffusion model](https://huggingface.co/CompVis/stable-diffusion), a text-to-image latent diffusion model created by the researchers and engineers from CompVis, Stability AI and LAION. This notebook is based on [HuggingFace's StableDiffusion Notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb), which you should use if you wish to have more fine-grained control of the model through code, rather than this notebook's text-box interface."
      ],
      "metadata": {
        "id": "XGfoNsaeyYEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Environment Setup\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### HuggingFace Token:\n",
        "#@markdown To download the model, you must accept it's licence on HuggingFace and enter an auth token for this notebook:\n",
        "#@markdown 1. [Sign up for a Hugging Face account](https://huggingface.co/join).\n",
        "#@markdown 2. Go to [the Stable Diffusion Model](https://huggingface.co/CompVis/stable-diffusion-v1-4) and accept the licence. Read through it first and make sure you agree to it!\n",
        "#@markdown 3. Go to the [Access Tokens page](https://huggingface.co/settings/tokens) and create a token with \"read\" permissions.\n",
        "#@markdown 4. Copy the token and paste it here. Make sure not to share this token with anyone.\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "model = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "## Ensure a GPU is available\n",
        "import os\n",
        "if os.system(\"nvidia-smi\") != 0:\n",
        "  print(\"No GPU attached to this Colab instance. Please click Runtime>Change Runtime Type and change \\\"None\\\" to \\\"GPU\\\"\")\n",
        "  exit(1)\n",
        "\n",
        "## Install necessary libraries\n",
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "\n",
        "## Imports\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from huggingface_hub import notebook_login\n",
        "from PIL import Image\n",
        "\n",
        "## Download the Model\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=token)\n",
        "\n",
        "## Move the model to the GPU\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "_0yyeYOA0seK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Image Generation ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
        "\n",
        "#@markdown ### Prompt:\n",
        "#@markdown Set here what prompt you would like the images to be generated from\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown Image Width\n",
        "width = 512 #@param {type:\"integer\"}\n",
        "#@markdown Image Height\n",
        "height = 512 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Advanced Model Parameters:\n",
        "#@markdown Random seed passed to the generator. The same seed will always yield the same image output from the same prompt (assuming all other values are also the same)\n",
        "random_seed = 0 #@param {type:\"number\"}\n",
        "#@markdown Should the provided random seed (above) be used for the generator?\n",
        "use_random_seed = False #@param {type:\"boolean\"}\n",
        "#@markdown How many generation steps to run for each image. Fewer steps give less defined and realistic detail.\n",
        "steps = 50 #@param {type:\"integer\"}\n",
        "#@markdown Guidance scale\n",
        "guidance_scale = 8 #@param {type:\"number\"}\n",
        "\n",
        "# Random seeding\n",
        "import torch\n",
        "image_generator = torch.Generator(\"cuda\")\n",
        "if use_random_seed:\n",
        "  image_generator.manual_seed(random_seed)\n",
        "  print(\"Used provided random seed for the generator\")\n",
        "else:\n",
        "  image_generator.seed()\n",
        "  print(\"Used a new random seed for the generator\")\n",
        "print(f\"Generator Seed: {image_generator.initial_seed()}\")\n",
        "\n",
        "# Guidance scale\n",
        "print(f\"Guidance Scale: {guidance_scale}\")\n",
        "\n",
        "# Generate Output Image\n",
        "with autocast(\"cuda\"):\n",
        "  image = pipe(prompt, generator=image_generator, num_inference_steps=steps, guidance_scale=guidance_scale, height=height, width=width)[\"sample\"][0]\n",
        "\n",
        "image"
      ],
      "metadata": {
        "id": "-DhFvgGNAvsM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}